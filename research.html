<html>
<head>
<link rel="stylesheet" href="mystyles.css">
</head>
<body>
  <div style="margin:100px">

<h1 class="myh1">Fundamental research:</h1>
    
    <p class="myp">
    <b>Overaching goals </b> 
      Learning, and more generally information processing and storing, seems to work extremely well in biological systems. A 
      <a href="https://www.sciencedirect.com/science/article/pii/S0003347214004771" style="text-decoraction:none; color: #ed517a">bee</a> 
      (an animal with less than with less than a million neurons, and fewer than 10 billion synapses) can perform remarkably 
      sophisticated optimisation of its behavior for the future. Machine learning algorithms have also achieved remarkable performance in recent years,
      however they are not flawless. For example, research has demonstrated that it can be easy to fool the algorithm into 
      misreading a stop sign simply by putting four small stickers on the face of the sign. It is <a href="https://towardsdatascience.com/the-future-of-ai-is-decentralized-848d4931a29a" style="text-decoraction:none; color: #ed517a">estimated</a> 
      that the training of a model like GPT-3 may cost millions of dollars. 
      This raises the question of whether we can define more efficient and robust learning models and algorithms. 
      My group focuses on the design of computational 
      models to improve information processing in artificial intelligent systems relying on a broad range of tools from 
      applied probability, signal processing, statistical mechanics and 
      mathematical modeling. 
  </p>
    
<h1 class="myh1">Application areas:</h1>
    
    <p class="myp"><b>Privacy-preserving machine learning </b> Algorithms are deployed for processing a lot of sensitive data, 
    such as data collected by hospitals or by internet of things devices in your home. Research has shown that many machine learning 
    and data processing algorithms are vulnerable to so-called attacks that are able to extract this sensitive information from 
    the model's outputs or parameters. This shows the need for defining privacy-preserving algorithms. Projects include analysing what models 
    are more sensitive to the attacks, understanding where in a deep neural network what kind of information is stored, and modifying 
      the learning algorithms to be more robust to information extraction attacks. </p>
    
    <p class="myp"><b> Optimal control and robotics </b> More on this soon. <p>
    
    <p class="myp"><b> Deep Brain Stimulation </b> More on this soon. <p>

</ul>

</div>
</body>
</html>
