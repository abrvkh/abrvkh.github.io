<html>
<body>
  <div style="margin:100px">

<p>My current research interests:</p>
<ul>
<li><p style="font-size:15px"><b>The design of effective learning dynamics in nonconvex, distributed settings.</b>
  <ul>
  <li> <b>Using interacting agents.</b> One can run independent copies of the optimization algorithm or allow for the separate runs to interact. Can this help speed up convergence
    or facilitate convergence to more robust and stable solutions?
  Some interesting papers:
  <a href="http://proceedings.mlr.press/v75/cheng18a/cheng18a.pdf" style="text-decoration:underline;color: #ed517a"> [1] </a>
  <a href="https://arxiv.org/pdf/2105.12049.pdf" style="text-decoration:underline;color: #ed517a"> [2] </a>
  <a href="https://arxiv.org/pdf/1811.08413.pdf" style="text-decoration:underline;color: #ed517a"> [3] </a>
  <a href="https://arxiv.org/pdf/2007.07704.pdf" style="text-decoration:underline;color: #ed517a"> [4] </a>
  <a href="https://arxiv.org/pdf/1212.0876.pdf" style="text-decoration:underline;color: #ed517a"> [5] </a>
  </li>

  <li style="font-size:15px">><b>Mirror descent.</b> The mirror map in mirror descent allows to better fit to the constraint set and problem geometry. In what settings do which mirror maps help speed up convergence? How to choose the mirror map in a good way?
    Some interesting papers:
    <a href="https://ieeexplore.ieee.org/abstract/document/7004065?casa_token=joHnF32cqqYAAAAA:ckCLPKuqUSZW-WY9iT6NqjtD9HX-6xLh8H58XCFpJrN98pIjprL4xYemeXZg0uT63u8EGgrh" style="text-decoration:underline;color: #ed517a"> [1] </a>
    <a href="http://proceedings.mlr.press/v119/hendrikx20a/hendrikx20a.pdf" style="text-decoration:underline;color: #ed517a"> [2] </a>
    <a href="http://www.numdam.org/article/SMAI-JCM_2018__4__57_0.pdf" style="text-decoration:underline;color: #ed517a"> [3] </a>
  </li>

  <li style="font-size:15px">> <b> Efficient communication.</b> In a setting where data is distributed across devices or servers we are interested
    in how to define the communication structure between the nodes/particles to balance communication costs and convergence speed.
    Some interesting papers:
    <a href="https://epubs.siam.org/doi/pdf/10.1137/120901866?casa_token=IKKfgWvOY_gAAAAA:srIV1RIjUr4XH6MZlqFgBsfzxU2sCAhGDB8UPmhLjmBlnjy_zlMf-ZXA_AMipyZmD3cZdJt8GA" style="text-decoration:underline;color: #ed517a"> [1] </a>
    <a href="https://www.ma.imperial.ac.uk/~pavl/Optimizing_dynamics_using_spectral_gaps___ICML21_Workshop_on_beyond_first_order.pdf" style="text-decoration:underline;color: #ed517a"> [2] </a>
  </li>

  <li style="font-size:15px">><b>Information processing in the brain and explainable neural networks. </b> Here I am interested in
    analysing what kind of information is stored where in deep neural networks and how this depends on the underlying optimisation
    algorithm and model architecture.
    <a href="https://distill.pub/2017/feature-visualization/" style="text-decoration:underline;color: #ed517a"> [1] </a>
    <a href="https://openaccess.thecvf.com/content_cvpr_2015/papers/Mahendran_Understanding_Deep_Image_2015_CVPR_paper.pdf" style="text-decoration:underline;color: #ed517a"> [2] </a>
    <a href="https://arxiv.org/abs/1711.00165" style="text-decoration:underline; color: #ed517a"> [3]</a>
    <a href="https://arxiv.org/pdf/2107.05438.pdf" style="text-decoration:underline;color: #ed517a"> [4] </a>
  </li>
  </ul>
  </p>
<li><p style="font-size:15px"><b>Applications: </b>
<ul>
  <li style="font-size:15px">> <b> Privacy-preserving machine learning.</b> Prior work has shown that model parameters
  can leak private information about the datasets they were trained on. Using the tools discussed above
  we can analyse which parts of a neural network contain the most private information.
  We hope to answer the following question: how can we define learning dynamics that have a satisfactory trade-off
  between privacy and accuracy?
  Some interesting papers:
  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8835269&casa_token=MmEHM6bEqo0AAAAA:qN0712JfSBVwo_VEaFihevEbnLD2PvQlB4LFlKjZbgmzHrgMRnbUQz02wsaOgIwJ75CgNQ-M" style="text-decoration:underline;color: #ed517a"> [1] </a>
  <a href="https://dl.acm.org/doi/pdf/10.1145/3386901.3388946?casa_token=FqJfdUc-kn8AAAAA:jMarXbIU9SKBsFNEV3QyWRG8cDgU3g9Aw_CjcvyKd0VSgUTqljuMwLsDxSlU-V2EQiAb8ISRG4V5" style="text-decoration:underline;color: #ed517a"> [2] </a>
</li>

<li style="font-size:15px"><b>Market dynamics and decentralized finance.</b> Here I am interested in analysing market dynamics
  by modeling the asset prices as interacting stochastic differential equations. I would also like to better understand the dynamics of
  decentralized exchanges.
  Some interesting papers:
  <a href="https://arxiv.org/pdf/2203.07550.pdf" style="text-decoration:underline;color: #ed517a"> [1] </a>
  <a href="https://arxiv.org/pdf/1904.05234.pdf" style="text-decoration:underline;color: #ed517a"> [2] </a>
</li>
  </p>


</ul>
<p>Feel free to get in touch if any of the above interest you. </p>

</div>
</body>
</html>
